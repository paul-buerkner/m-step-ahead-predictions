---
title: "PSIS assisted m-step-ahead predictions for time-series models"
author: Paul Buerkner, Aki Vehtari
output:
  html_document: default
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  cache=TRUE, 
  message=FALSE, 
  error=FALSE,
  warning=FALSE, 
  comment=NA, 
  dev = "png",
  dpi = 150,
  fig.asp = 0.618,
  fig.width = 5,
  out.width = "60%",
  fig.align = "center"
)
library(brms)
library(loo)
theme_set(theme_default())
SEED <- 1234
set.seed(SEED)
```

## Introduction

The idea of m-step-ahead predictions (m-SAP) for time-series models is to predict $m$ observations ahead using only past observations of the time-series and no future observations. Doing exact m-SAP requires repeatedly fitting the model for each set of $m$ observations to be predicted. This is usually very time-intensive in particular for Bayesian models and so we seek to approximate m-SAP using as few refits of the model as possible.

## m-step-ahead predictions

Assume we have a time-series of observations $(y_1, y_2, ..., y_N)$, then the goal of m-SAP is to compute the predictive density
$$
p(y_{i<m} | y_{<i}) = p(y_i, ..., y_{i + m - 1} | y_{1},...,y_{i-1})
$$ 
for all $i$ between $L + 1$ and $N - m + 1$, where $L$ is the minimum number of values required to make predictions (e.g., $L = 10$ if we want to start with predicting the $11$th observation). The quantities $p(y_{i<m} | y_{<i})$ can be computed as follows with the help of the posterior distribution $p(\theta | y_{<i})$ of the parameters $\theta$ based on the $i-1$ earliest observations of the time-series:
$$
p(y_{i<m} \,| \, y_{<i}) = \int p(y_{i<m} \,| \, y_{<i}, \theta) \, p(\theta\,|\,y_{<i}) \,d\theta.
$$
Having obtained $S$ random draws $\theta_{<i}^{(s)}$ ($s = 1,...,S$) of the posterior distribution $p(\theta\,|\,y_{<i})$, we can estimate $p(y_i | y_{<i})$ by means of

$$
p(y_{i<m} \,|\, y_{<i}) \approx \sum_{s=1}^S p(y_{i<m} \,|\, y_{<i}, \theta_{<i}^{(s)}).
$$

In the following, we consider factorized models in which the response values are conditionally independent given the parameters and the likelihood
can be written in the familiar form

$$
p(y \,|\, \theta) = \prod_{i=1}^N p(y_i \,|\, \theta).
$$
In this case, $p(y_{i<m} \,|\, y_{<i}, \theta_{<i})$ reduces to $\prod_{j = i}^{i + m -1} p(y_j \,|\, \theta_{<i})$.

## Approximate m-SAP using integrated importance-sampling

To reduce the number of models that need to be fitted for the purpose of obtaining $p(y_{i<m} \,|\, y_{<i})$, we propose the following algorithm. Starting at the end of the time-series (i.e. $i = N - m + 1$), we compute $p(y_{i<m} \,|\, y_{<i})$ with approximate leave-m-out cross-validation using integrated importance sampling (Vehtari et al., 2016, Section 3.6.1):

$$
 p(y_{i<m} \,|\, y_{<i}) \approx
   \frac{ \sum_{s=1}^S p(y_{i<m} \,|\, \theta^{(s)}) \, w_i^{(s)}}{ \sum_{s=1}^S w_i^{(s)}},
$$

where $w_i^{(s)}$ are importance weights and $\theta^{(s)}$ are draws from the posterior distribution based on all observations. To obtain $w_i^{(s)}$, we first compute the raw importance ratios

$$
r_i^{(s)} \propto \frac{1}{\prod_{j = i}^N p(y_j \,|\, \,\theta^{(s)})}
$$

and then stabilize them using Pareto smoothed importance sampling (PSIS, Vehtari et al, 2017ab). We then gradually decrease $i$ by $1$ and repeat the process. At some observation $i$, the variability in $r_i^{(s)}$ will become too large to that the PSIS approximation will fail (Pareto-k-estimates greater than $0.7$). Then we refit the model using only observations up to the $i$th one and restart the process until we arrived at the $L+1$th observation, where $L$ is the minimum sample size required to make predictions ($L=0$ if predictions of all observations should be computed).

## Autoregressive models

Autoregressive (AR) models are one of the classic time-series models. An AR-model of order $p$ can be defined as

$$
Y_i = \eta_i + \sum_{k = 1}^p \varphi_k Y_{i - k} + \varepsilon_i,
$$
where $\eta_i$ is the linear predictor of observation $i$, $\phi_k$ are the autoregressive parameters and $\varepsilon_i$ are pairwise independent errors, which are usually assumed to be normally distributed with equal variance $\sigma^2$. The model implies a recursive formula that allows to compute the right-hand side of the above equation for observation $i$ based on the equations' solution for all past observations $1$ to $i-1$.

## Case Study: Annual measurements of the level of Lake Huron

To illustrate the application of m-SAP, we will use the annual measurements of the level (in feet) of Lake Huron 1875â€“1972 as a case study, which is shipped natively with **R**.

```{r}
plot(LakeHuron)
```

The above plot shows rather strong autocorrelation of the time-series as well as some trend towards lower levels for later points in time. For model fitting, we turn the time-series into a data frame.

```{r}
N <- length(LakeHuron)
df <- data.frame(y = as.numeric(LakeHuron))
df$time <- 1:N
```

and then specify an AR(2) model on these data using the **brms** package.

```{r fit, results = "hide"}
control <- list(adapt_delta = 0.95)
fit <- brm(
  y ~ 1, data = df, autocor = cor_ar(~time, p = 2), 
  control = control, seed = SEED
)
```

The model implied predictions along with the observed values can be plotted, which reveals a rather good fit to the data.

```{r, cache = FALSE}
pred <- cbind(df, predict(fit))
names(pred)[5:6] <- c("Q2.5", "Q97.5")
ggplot(pred, aes(time, Estimate)) +
  geom_smooth(
    aes(ymin = Q2.5, ymax = Q97.5),
    stat = "identity"
  ) +
  geom_point(aes(time, y), inherit.aes = FALSE)
```

To allow for reasonable predictions of future values, we will require at least $L = 15$ observations to make predictions.

```{r}
L <- 15
```

we perform approximate leave-one-out cross-validation (LOO-CV), for the purpose of later comparison with exact and approximate 1-SAP.

```{r, cache = FALSE}
loo(log_lik(fit)[, (L+1):N])
```

## 1-step-ahead predictions leaving out all future values

The most basic version of m-SAP is 1-SAP in which we predict only one step ahead. In this case, $y_{i<m}$ simplifies to $y_{i}$ and the above described algorithm becomes considerably simpler.

### Exact 1-step-ahead predictions

As a benchmark to approximate 1-SAP, we are going to compute exact 1-SAP, by first computing the exact log-likelihood values

```{r exact_loglik, results="hide"}
loglik <- matrix(nrow = nsamples(fit), ncol = N)
for (i in N:max(L + 1, 2)) {
  fit_i <- update(fit, newdata = df[-(i:N), ], recompile = FALSE, chains = 1)
  loglik[, i] <- log_lik(fit_i, newdata = df[1:i, ])[, i]
}
```

and then compute the exact expected log predictive density (elpd) on that basis.

```{r, cache = FALSE}
log_mean_exp <- function(x) {
  # more stable than log(mean(exp(x)))
  max_x <- max(x)
  max_x + log(sum(exp(x - max_x))) - log(length(x))
}
exact_elpds_1sap <- apply(loglik, 2, log_mean_exp)
(exact_elpd_1sap <- sum(exact_elpds_1sap[-(1:L)]))
```

### Approximate 1-step-ahead predictions

For illustrationary purposes, we first compute approximate 1-SAP without refitting. This will of course be a poor approximation of exact 1-SAP in particular if the Pareto-k-estimates increase rather quickly beyond the threshold of $0.7$ up the which PSIS tends to produce stable results.

```{r loglik}
approx_elpds_1sap_no_refit <- rep(NA, nrow(df))
loglik <- log_lik(fit)
logr <- matrix(nrow = nsamples(fit), ncol = nrow(df))
for (i in N:(L + 1)) {
  logr[, i] <- - rowSums(loglik[, i:N, drop = FALSE])
  psis_part <- suppressWarnings(psis(logr[, i:N]))
  w_i <- exp(psis_part$log_weights[, 1])
  approx_elpds_1sap_no_refit[i] <- 
    log(sum(exp(loglik[, i]) * w_i) / sum(w_i))
}
```

The plot below indicates that indeed the Pareto-k-estimates go over the roof when not refitting the model at some point.

```{r, cache = FALSE}
is_na <- apply(logr, 2, anyNA)
plot(psis(logr[, !is_na]))
```

Consequently, it is not surprising that the resulting approximate elpd is far away for the exact elpd.

```{r, cache = FALSE}
(approx_elpd_1sap_no_refit <- sum(approx_elpds_1sap_no_refit, na.rm = TRUE))
```

Next, we compute approximate 1-SAP with refit at observations where Pareto-k-estimates exceed the threshold of $0.7$.

```{r}
k_thres <- 0.7
```

The code becomes a little bit more involved to handle the refitting procedure. Note that we compute exact 1-SAP at the refitting points. This comes with no additional computational costs since we had to refit the model anyway. 

```{r refit_loglik, results="hide"}
loglik <- logr <- matrix(nrow = nsamples(fit), ncol = nrow(df))
approx_elpds_1sap <- rep(NA, nrow(df))
fit_part <- fit
i_refit <- N
refits <- NULL
for (i in N:(L + 1)) {
  loglik[, i] <- log_lik(fit_part)[, i]
  logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
  psis_part <- suppressWarnings(psis(logr[, i:i_refit]))
  if (any(psis_part$diagnostics$pareto_k > k_thres)) {
    # refit the model based on the first i-1 observations
    i_refit <- i
    refits <- c(refits, i)
    fit_part <- update(
      fit_part, newdata = df[1:(i-1), ], 
      recompile = FALSE, chains = 1
    )
    loglik[, i] <- log_lik(fit_part, newdata = df[1:i, ])[, i]
    logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
    approx_elpds_1sap[i] <- log_mean_exp(loglik[, i])
  } else {
    w_i <- exp(psis_part$log_weights[, 1])
    approx_elpds_1sap[i] <- log(sum(exp(loglik[, i]) * w_i) / sum(w_i))
  }
}
```

We see that the final Pareto-k-estimates are mostly well below the threshold and that we only needed to refit the model `r length(refits)` times at observations `r refits`.

```{r, cache = FALSE}
is_na <- apply(logr, 2, anyNA)
plot(psis(logr[, !is_na]))
```

The approximate elpd is remarkably similar to the exact elpd compute above, which indicates our algorithm to compute approximate 1-SAP worked well for the present data and model.

```{r, cache = FALSE}
(approx_elpd_1sap <- sum(approx_elpds_1sap, na.rm = TRUE))
```

Plotting exact against approximate predictions, we see that no approximation value deviates far from its exact counterpart providing further evidence for the goodness of our approximation.

```{r, cache = FALSE}
dat_elpd <- data.frame(
  approx_elpd = approx_elpds_1sap,
  exact_elpd = exact_elpds_1sap
)

outlier0.5 <- which(abs(dat_elpd$approx_elpd - dat_elpd$exact_elpd) > 0.5)
outlier0.25 <- which(abs(dat_elpd$approx_elpd - dat_elpd$exact_elpd) > 0.25)

ggplot(dat_elpd, aes(x = approx_elpd, y = exact_elpd)) +
  geom_abline(color = "gray30") +
  geom_point(size = 2) +
  geom_point(data = dat_elpd[outlier0.5, ], size = 3, color = "red3") +
  xlab("Approximate elpds") +
  ylab("Exact elpds") 
```

No observation shows a distance between exact and approximate elpd of more than $0.5$. The `r outlier0.25`th observations show a distance between exact and approximate elpd of more than $0.25$, which has little influence on the overall elpd.

## m-step-ahead predictions leaving out all future values

To illustrate the application of m-SAP if $m > 1$, we compute exact and approximate 4-SAP and on the AR(2) model fitted to the Lake Huron data.

### Exact m-step-ahead predictions

The necessary steps are the same as for 1-SAP with the exception that the log-likelihood values of interest are now the sums of the log-likelihood values of four consequtive observations.

```{r exact_loglikm, results="hide"}
m <- 4
loglikm <- matrix(nrow = nsamples(fit), ncol = nrow(df))
for (i in (N - m + 1):max(L + 1, 2)) {
  fit_i <- update(fit, newdata = df[-(i:N), ], recompile = FALSE, chains = 1)
  ll <- log_lik(fit_i, newdata = df[1:(i + m - 1), ])
  loglikm[, i] <- rowSums(ll[, i:(i + m - 1)])
}
```

```{r, cache = FALSE}
exact_elpds_4sap <- apply(loglikm, 2, log_mean_exp)
(exact_elpd_4sap <- sum(exact_elpds_4sap, na.rm = TRUE))
```

### Approximate m-step-ahead predictions

Similar to the exact 4-SAP, computing the approximate 4-SAP is a little bit more involved than the 1-SAP counterpart although the principle idea as well as the applied importance weights remain the same.

```{r refit_loglikm, results="hide"}
loglikm <- loglik <- logr <- matrix(nrow = nsamples(fit), ncol = nrow(df))
approx_elpds_4sap <- rep(NA, nrow(df))
fit_part <- fit
i_refit <- N-m+1
refits <- NULL
loglik[, (N - m + 2):N] <- log_lik(fit_part)[, (N - m + 2):N]
for (i in (N - m + 1):(L + 1)) {
  ll <- log_lik(fit_part, newdata = df[1:(i + m - 1), ])
  loglikm[, i] <- rowSums(ll[, i:(i + m - 1)])
  loglik[, i] <- ll[, i]
  logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
  psis_part <- suppressWarnings(psis(logr[, i:i_refit]))
  if (any(psis_part$diagnostics$pareto_k > k_thres)) {
    # refit the model based on the first i-1 observations
    i_refit <- i
    refits <- c(refits, i)
    fit_part <- update(
      fit_part, newdata = df[1:(i-1), ], 
      recompile = FALSE, chains = 1
    )
    ll <- log_lik(fit_part, newdata = df[1:(i + m - 1), ])
    loglik[, i] <- ll[, i]
    loglikm[, i] <- rowSums(ll[, i:(i + m - 1)])
    logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
    approx_elpds_4sap[i] <- log_mean_exp(loglikm[, i])
  } else {
    w_i <- exp(psis_part$log_weights[, 1])
    approx_elpds_4sap[i] <- log(sum(exp(loglikm[, i]) * w_i) / sum(w_i))
  }
}
```

Again, we see that the final Pareto-k-estimates are mostly well below the threshold and that we only needed to refit the model `r length(refits)` times at observations `r refits`.

```{r, cache = FALSE}
is_na <- apply(logr, 2, anyNA)
plot(psis(logr[, !is_na]))
```

Similar to 1-SAP, the approximate 4-SAP is very close to the exact counterpart.

```{r, cache = FALSE}
(approx_elpd_4sap <- sum(approx_elpds_4sap, na.rm = TRUE))
```

Plotting exact against approximate pointwise predictions confirms this result.

```{r, cache = FALSE}
dat_elpd <- data.frame(
  approx_elpd = approx_elpds_4sap,
  exact_elpd = exact_elpds_4sap
)

outlier2 <- which(abs(dat_elpd$approx_elpd - dat_elpd$exact_elpd) > 2)
outlier1 <- which(abs(dat_elpd$approx_elpd - dat_elpd$exact_elpd) > 1)

ggplot(dat_elpd, aes(x = approx_elpd, y = exact_elpd)) +
  geom_abline(color = "gray30") +
  geom_point(size = 2) +
  geom_point(data = dat_elpd[outlier2, ], size = 3, color = "red3") +
  xlab("Approximate elpds") +
  ylab("Exact elpds")
```

## 1-step-ahead predictions leaving out blocks of future values

Depending on the particular time-series model and data, the Pareto-k-estimates will exceed $0.7$ rather quickly (i.e. after only few observations) and thus many refits may be required even if applying the above described algorithm. In this case, an option is to exclude only a number of $B$ future values which directly follow the observations to be predicted while keeping all more distant future values $B+1$ to $N$. This will usually result in lower Pareto-k-estimates and thus less refitting. The block-m-SAP resembles the basic m-SAP closely only if values in the distant future (that is farer away than $B$ steps) contain little information about the current observations being predicted. Whether this assumption is justified depends on the data and applied time-series model. We are going to illustrate this approach using block-1-SAP.

### Exact 1-step-ahead predictions

The related code changes little with the exception that we now define a block size $B$ of left-out observations, which we set to $B = 10$ for the present case study.

```{r exact_loglik_block, results="hide"}
B <- 10
loglik <- matrix(nrow = nsamples(fit), ncol = nrow(df))
for (i in N:(L + 1)) {
  to <- min(i + B - 1, N)
  fit_i <- update(fit, newdata = df[-(i:to), ], recompile = FALSE, chains = 1)
  loglik[, i] <- log_lik(fit_i, newdata = df[1:i, ])[, i]
}
```

Comparing the exact block-1-SAP to the exact 1-SAP reveals substantial differences demonstrating that the assumption about distant future values containing no additional information is probably not justified in the present case.

```{r, cache = FALSE}
exact_elpds_1sap_block <- apply(loglik, 2, log_mean_exp)
(exact_elpd_1sap_block <- sum(exact_elpds_1sap_block, na.rm = TRUE))
```

### Approximate 1-step-ahead predictions

We compute approximate block-1-SAP as follows.

```{r refit_loglik_block, results="hide"}
loglik <- logr <- matrix(nrow = nsamples(fit), ncol = nrow(df))
approx_elpds_1sap_block <- rep(NA, nrow(df))
fit_part <- fit
i_refit <- N
refits <- NULL
for (i in N:(L + 1)) {
  loglik[, i] <- log_lik(fit_part)[, i]
  to <- min(i + B - 1, i_refit)
  logr[, i] <- - rowSums(loglik[, i:to, drop = FALSE])
  psis_part <- suppressWarnings(psis(logr[, i:i_refit]))
  if (any(psis_part$diagnostics$pareto_k > k_thres)) {
    # refit the model without a block of B observations
    i_refit <- i
    refits <- c(refits, i)
    fit_part <- update(
      fit_part, newdata = df[-(i:to), ], 
      recompile = FALSE, chains = 1
    )
    loglik[, i] <- log_lik(fit_part, newdata = df[1:i, ])[, i]
    logr[, i] <- - rowSums(loglik[, i:to, drop = FALSE])
    approx_elpds_1sap_block[i] <- log_mean_exp(loglik[, i])
  } else {
    w_i <- exp(psis_part$log_weights[, 1])
    approx_elpds_1sap_block[i] <- log(sum(exp(loglik[, i]) * w_i) / sum(w_i))
  }
}
```

We needed only a single refit at observation `r refits`, which is remarkable given that we deal with a time-series of 98 observations in total of which we predicted `r 98 - L` observations. 

```{r, cache = FALSE}
is_na <- apply(logr, 2, anyNA)
plot(psis(logr[, !is_na]))
```

Consequently, it is not surprising that approximate block-1-SAP matches the exact counterpart closely.

```{r, cache = FALSE}
(approx_elpd_1sap_block <- sum(approx_elpds_1sap_block, na.rm = TRUE))
```

This is also visible in the plot of approximate against exact predictions.

```{r, cache = FALSE}
dat_elpd <- data.frame(
  approx_elpd = approx_elpds_1sap_block,
  exact_elpd = exact_elpds_1sap_block
)

outlier0.5 <- which(abs(dat_elpd$approx_elpd - dat_elpd$exact_elpd) > 0.5)
outlier0.25 <- which(abs(dat_elpd$approx_elpd - dat_elpd$exact_elpd) > 0.25)

ggplot(dat_elpd, aes(x = approx_elpd, y = exact_elpd)) +
  geom_abline(color = "gray30") +
  geom_point(size = 2) +
  geom_point(data = dat_elpd[outlier0.5, ], size = 3, color = "red3") +
  xlab("Approximate elpds") +
  ylab("Exact elpds")
```

## Conclusion

In the present case study, we have shown how to approximate m-step-ahead predictions in time-series models by means of Pareto-smoothed importance-sampling using as few refits of the model as possible. At least for the present data and model, our algorithm provides reasonably stable and accurate results depite requiring very few refits.

<br />

## References

Vehtari A., Mononen T., Tolvanen V., Sivula T., & Winther O. (2016). Bayesian leave-one-out cross-validation approximations for Gaussian latent variable models. *Journal of Machine Learning Research*, 17(103), 1--38. [Online](http://jmlr.org/papers/v17/14-540.html).

Vehtari A., Gelman A., & Gabry J. (2017a). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. *Statistics and Computing*, 27(5), 1413--1432. doi:10.1007/s11222-016-9696-4. [Online](http://link.springer.com/article/10.1007/s11222-016-9696-4). [arXiv preprint arXiv:1507.04544](https://arxiv.org/abs/1507.04544).

Vehtari A., Gelman A., & Gabry J. (2017b). Pareto smoothed importance sampling. [arXiv preprint arXiv:1507.02646](https://arxiv.org/abs/1507.02646).

<br />

## Appendix

### Appendix: Session information

```{r}
sessionInfo()
```

### Appendix: Licenses

* Code &copy; 2018, Paul Buerkner, Aki Vehtari, licensed under BSD-3.
* Text &copy; 2018, Paul Buerkner, Aki Vehtari, licensed under CC-BY-NC 4.0.
