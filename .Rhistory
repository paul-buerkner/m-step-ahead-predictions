error=FALSE,
warning=FALSE,
comment=NA,
dev = "png",
dpi = 150,
fig.asp = 0.618,
fig.width = 5,
out.width = "60%",
fig.align = "center"
)
library(brms)
set.seed(1234)
ggplot(pred, aes(t, Estimate)) +
geom_smooth(
aes(ymin = X2.5.ile, ymax = X97.5.ile),
stat = "identity"
) +
geom_point(aes(t, y), inherit.aes = FALSE)
fit_ar
fit_ar1
fit_ar1_test <- brm(y ~ 1, df, autocor = cor_ar(~t, cov = TRUE))
fit_ar1_test
bayes_R2(fit_ar1, fit_ar1_test)
bayes_R2(fit_ar1)
bayes_R2(fit_ar1_test)
LOO(fit_ar1)
LOO(fit_ar1, fit_ar1_test)
fit_ar1
fit_ar1_test
df$ym1 <- c(0, df$ym1[-nrow(df)])
df$ym1
df$ym1 <- c(0, df$y[-nrow(df)])
df$ym1
df
fit_ar1_test <- brm(y ~ ym1, df)
fit_ar_test
fit_ar1_test
LOO(fit_ar1, fit_ar1_test)
i <- N
log_lik(fit_ar1, newdata = df[i, ])
N <- max(df$t)
L <- 10
loglik <- rawr <- matrix(nrow = nsamples(fit), ncol = nrow(df))
fit_ar1 <- fit_ar1_test
log_lik(fit_ar1, newdata = df[i, ])
i = N
log_lik(fit_ar1, newdata = df[i, ])
apply(matrix(1:4, 2, 2), 1, "Sum")
apply(matrix(1:4, 2, 2), 1, "um")
apply(matrix(1:4, 2, 2), 1, "sum")
matrix(1:4, 2, 2
matrix(1:4, 2, 2)
rowSums(matrix(1:4, 2, 2))
pred <- cbind(df, predict(fit_ar1))
pred <- cbind(df, predict(fit_ar1))
names(pred) <- make.names(names(pred))
pred <- cbind(df, predict(fit_ar1))
names(pred) <- make.names(names(pred))
ggplot(pred, aes(t, Estimate)) +
geom_smooth(
aes(ymin = X2.5.ile, ymax = X97.5.ile),
stat = "identity"
) +
geom_point(aes(t, y), inherit.aes = FALSE)
N <- max(df$t)
loglik <- logr <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
logr[, i] <- - rowSums(loglik[, i:N, drop = FALSE])
N <- max(df$t)
L <- 10
for (i in N:(L + 1)) {
loglik[, i] <- log_lik(fit_ar1, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:N, drop = FALSE])
}
N <- max(df$t)
L <- 10
loglik <- logr <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df) - L)
str(loglik)
for (i in N:(L + 1)) {
loglik[, i] <- log_lik(fit_ar1, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:N, drop = FALSE])
}
N <- max(df$t)
L <- 10
loglik <- logr <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
for (i in N:(L + 1)) {
loglik[, i] <- log_lik(fit_ar1, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:N, drop = FALSE])
}
loglik <- loglik[, -(1:L)]
logr <- logr[, -(1:L)]
psis(logr)
library(loo)
psis(logr)
plot(psis(logr))
LOO(fit_ar1)
plot(psis(logr[, 90:100]))
N <- max(df$t)
L <- 10
for (i in N:(L + 1)) {
loglik[, i] <- log_lik(fit_ar1, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:N, drop = FALSE])
}
N <- max(df$t)
L <- 10
loglik <- logr <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
for (i in N:(L + 1)) {
loglik[, i] <- log_lik(fit_ar1, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:N, drop = FALSE])
}
plot(psis(logr[, 90:100]))
plot(psis(logr))
psis(logr[, 100])
str(plot(psis(logr)))
str(psis(logr[, 100]))
str(psis(logr[, 99:100]))
colnames(predict(fit_ar1))
any(NA)
methods(class = "psis")
rm(fit_ar1_test)
loglik <- logr <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
for (i in N:(L + 1)) {
loglik[, i] <- log_lik(fit_i, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:N, drop = FALSE])
psis_i <- psis(logr[, i:N])
if (any(psis_i$diagnostics$pareto_k > 0.7)) {
# refit the model based on the first i-1 observations
fit_i <- update(fit_i, newdata = df[1:(i-1), ], recompile = FALSE)
loglik[, i] <- log_lik(fit_i, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:N, drop = FALSE])
}
}
fit_i <- fit_ar1
for (i in N:(L + 1)) {
loglik[, i] <- log_lik(fit_i, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:N, drop = FALSE])
psis_i <- psis(logr[, i:N])
if (any(psis_i$diagnostics$pareto_k > 0.7)) {
# refit the model based on the first i-1 observations
fit_i <- update(fit_i, newdata = df[1:(i-1), ], recompile = FALSE)
loglik[, i] <- log_lik(fit_i, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:N, drop = FALSE])
}
}
?psis
plot(psis(logr[, -(1:L)]))
loglik <- logr <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
fit_i <- fit_ar1
for (i in N:(L + 1)) {
loglik[, i] <- log_lik(fit_i, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:N, drop = FALSE])
psis_i <- suppressWarnings(psis(logr[, i:N]))
if (any(psis_i$diagnostics$pareto_k > 0.7)) {
# refit the model based on the first i-1 observations
fit_i <- update(fit_i, newdata = df[1:i, ], recompile = FALSE)
loglik[, i] <- log_lik(fit_i, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:N, drop = FALSE])
}
}
plot(psis(logr[, -(1:L)]))
loglik <- logr <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
fit_i <- fit_ar1
for (i in N:(L + 1)) {
loglik[, i] <- log_lik(fit_i, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:N, drop = FALSE])
psis_i <- suppressWarnings(psis(logr[, i:N]))
if (any(psis_i$diagnostics$pareto_k > 0.7)) {
# refit the model based on the first i-1 observations
fit_i <- update(fit_i, newdata = df[1:i, ], recompile = FALSE, chains = 1)
loglik[, i] <- log_lik(fit_i, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:N, drop = FALSE])
}
}
?for
?"for"
```{r loglik_refit, results="hide"}
loglik <- logr <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
fit_i <- fit_ar1
i_refit <- N
for (i in N:(L + 1)) {
loglik[, i] <- log_lik(fit_i, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
psis_i <- suppressWarnings(psis(logr[, i:i_refit]))
if (any(psis_i$diagnostics$pareto_k > 0.7)) {
# refit the model based on the first i-1 observations
i_refit <- i
fit_i <- update(fit_i, newdata = df[1:i, ], recompile = FALSE, chains = 1)
loglik[, i] <- log_lik(fit_i, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
}
}
plot(psis(logr[, -(1:L)]))
psis(logr[, i:i_refit])
str(psis(logr[, i:i_refit]))
rm(fit_i)
rm(psis_i)
loglik <- logr <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
elpd_approx <- rep(NA, nrow(df))
fit_part <- fit_ar1
i_refit <- N
for (i in N:(L + 1)) {
loglik[, i] <- log_lik(fit_part, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
psis_part <- suppressWarnings(psis(logr[, i:i_refit]))
if (any(psis_part$diagnostics$pareto_k > 0.7)) {
# refit the model based on the first i-1 observations
i_refit <- i
fit_part <- update(fit_part, newdata = df[1:i, ], recompile = FALSE)
loglik[, i] <- log_lik(fit_part, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
psis_part <- suppressWarnings(psis(logr[, i:i_refit]))
}
log_weights_i <- psis_part$log_weights[, 1]
elpd_approx[i] <- sum(loglik[, i] * log_weights_i) / sum(log_weights_i)
}
plot(psis(logr[, -(1:L)]))
sum(elpd_approx[-(1:L)])
LOO(fit_ar1)
df <- data.frame(y = arima.sim(list(ar = c(0.7, 0.5, -0.3), 100), t = 1:100)
df <- data.frame(y = arima.sim(list(ar = c(0.7, 0.5, -0.3), 100), t = 1:100)
df <- data.frame(y = arima.sim(list(ar = c(0.7, 0.5, -0.3), 100)), t = 1:100)
df <- data.frame(y = arima.sim(list(ar = c(0.7, 0.5, -0.3)), 100), t = 1:100)
ggplot(df, aes(t, y)) + geom_line()
fit_ar3 <- brm(y ~ 1, df, autocor = cor_arr(~t, p = 3))
fit_ar3 <- brm(y ~ 1, df, autocor = cor_arr(~t, r = 3))
fit_ar3
posterior_summary(fit_ar3)
fit_ar3
library(brms)
loglik <- logr <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
approx_elpds <- rep(NA, nrow(df))
fit_part <- fit_ar1
i_refit <- N
for (i in N:(L + 1)) {
loglik[, i] <- log_lik(fit_part, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
psis_part <- suppressWarnings(psis(logr[, i:i_refit]))
if (any(psis_part$diagnostics$pareto_k > 0.7)) {
# refit the model based on the first i-1 observations
i_refit <- i
fit_part <- update(fit_part, newdata = df[1:i, ], recompile = FALSE)
loglik[, i] <- log_lik(fit_part, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
psis_part <- suppressWarnings(psis(logr[, i:i_refit]))
}
lw_i <- psis_part$log_weights[, 1]
approx_elpds[i] <- log(sum(exp(loglik[, i]) * lw_i) / sum(lw_i))
}
# Chunk 1: setup
knitr::opts_chunk$set(
cache=TRUE,
message=FALSE,
error=FALSE,
warning=FALSE,
comment=NA,
dev = "png",
dpi = 150,
fig.asp = 0.618,
fig.width = 5,
out.width = "60%",
fig.align = "center"
)
library(brms)
library(loo)
set.seed(1234)
df <- data.frame(y = arima.sim(list(ar = c(0.7, 0.5, -0.3)), 100), t = 1:100)
ggplot(df, aes(t, y)) + geom_line()
df <- data.frame(y = arima.sim(list(ar = c(0.5)), 100), t = 1:100)
ggplot(df, aes(t, y)) + geom_line()
# Chunk 1: setup
knitr::opts_chunk$set(
cache=TRUE,
message=FALSE,
error=FALSE,
warning=FALSE,
comment=NA,
dev = "png",
dpi = 150,
fig.asp = 0.618,
fig.width = 5,
out.width = "60%",
fig.align = "center"
)
library(brms)
library(loo)
set.seed(1234)
df <- data.frame(y = arima.sim(list(ar = c(0.5)), 100), t = 1:100)
ggplot(df, aes(t, y)) + geom_line()
# fit_ar1 <- brm(y ~ 1, df, autocor = cor_ar(~t))
df$ym1 <- c(0, df$y[-nrow(df)])
fit_ar1 <- brm(y ~ ym1, df)
pred <- cbind(df, predict(fit_ar1))
names(pred) <- make.names(names(pred))
ggplot(pred, aes(t, Estimate)) +
geom_smooth(
aes(ymin = X2.5.ile, ymax = X97.5.ile),
stat = "identity"
) +
geom_point(aes(t, y), inherit.aes = FALSE)
loglik <- logr <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
approx_elpds <- rep(NA, nrow(df))
fit_part <- fit_ar1
i_refit <- N
for (i in N:(L + 1)) {
loglik[, i] <- log_lik(fit_part, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
psis_part <- suppressWarnings(psis(logr[, i:i_refit]))
if (any(psis_part$diagnostics$pareto_k > 0.7)) {
# refit the model based on the first i-1 observations
i_refit <- i
fit_part <- update(fit_part, newdata = df[1:i, ], recompile = FALSE)
loglik[, i] <- log_lik(fit_part, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
psis_part <- suppressWarnings(psis(logr[, i:i_refit]))
}
lw_i <- psis_part$log_weights[, 1]
approx_elpds[i] <- log(sum(exp(loglik[, i]) * lw_i) / sum(lw_i))
}
plot(psis(logr[, -(1:L)]))
(approx_elpd <- sum(approx_elpds[-(1:L)]))
loglik <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
for (i in N:(L + 1)) {
fit_i <- update(fit_ar, df[-(i:N), ], recompile = FALSE, chains = 1)
loglik[, i] <- log_lik(fit_i, newdata = df[i, ])
}
loglik <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
for (i in N:(L + 1)) {
fit_i <- update(fit_ar1, df[-(i:N), ], recompile = FALSE, chains = 1)
loglik[, i] <- log_lik(fit_i, newdata = df[i, ])
}
loglik <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
for (i in N:(L + 1)) {
fit_i <- update(fit_ar1, newdata = df[-(i:N), ], recompile = FALSE, chains = 1)
loglik[, i] <- log_lik(fit_i, newdata = df[i, ])
}
log_mean_exp <- function(x) {
# more stable than log(mean(exp(x)))
max_x <- max(x)
max_x + log(sum(exp(x - max_x))) - log(length(x))
}
exact_elpds <- apply(loglik, 2, log_mean_exp)
(exact_elpd <- sum(exact_elpds[-(1:L)]))
df <- data.frame(y = arima.sim(list(ar = c(0.5)), 100) + 5, t = 1:100)
df <- data.frame(y = arima.sim(list(ar = c(0.5, -0.3)), 100) + 5, t = 1:100)
fit_ar2 <- brm(y ~ 1, df, autocor = cor_arr(~t, r = 2))
fit_ar2
pred <- cbind(df, predict(fit_ar2))
names(pred) <- make.names(names(pred))
ggplot(pred, aes(t, Estimate)) +
geom_smooth(
aes(ymin = X2.5.ile, ymax = X97.5.ile),
stat = "identity"
) +
geom_point(aes(t, y), inherit.aes = FALSE)
fit_ar2_test <- brm(y ~ 1, df, autocor = cor_ar(~t, p = 2))
fit_ar2_test
LOO(fit_ar2, fit_ar2_test)
loglik <- logr <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
approx_elpds <- rep(NA, nrow(df))
fit_part <- fit_ar1
i_refit <- N
for (i in N:(L + 1)) {
loglik[, i] <- log_lik(fit_part, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
psis_part <- suppressWarnings(psis(logr[, i:i_refit]))
if (any(psis_part$diagnostics$pareto_k > 0.7)) {
# refit the model based on the first i observations
# could be improved by computed exact loo for the ith observation
i_refit <- i
fit_part <- update(fit_part, newdata = df[1:i, ], recompile = FALSE)
loglik[, i] <- log_lik(fit_part, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
psis_part <- suppressWarnings(psis(logr[, i:i_refit]))
}
w_i <- exp(psis_part$log_weights[, 1])
approx_elpds[i] <- log(sum(exp(loglik[, i]) * w_i) / sum(w_i))
}
# Chunk 1: setup
knitr::opts_chunk$set(
cache=TRUE,
message=FALSE,
error=FALSE,
warning=FALSE,
comment=NA,
dev = "png",
dpi = 150,
fig.asp = 0.618,
fig.width = 5,
out.width = "60%",
fig.align = "center"
)
library(brms)
library(loo)
set.seed(1234)
# Chunk 2
df <- data.frame(y = arima.sim(list(ar = c(0.5, -0.3)), 100) + 5, t = 1:100)
df$ym1 <- c(0, df$y[-nrow(df)])
ggplot(df, aes(t, y)) + geom_line()
loglik <- logr <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
approx_elpds <- rep(NA, nrow(df))
fit_part <- fit_ar1
i_refit <- N
for (i in N:(L + 1)) {
loglik[, i] <- log_lik(fit_part, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
psis_part <- suppressWarnings(psis(logr[, i:i_refit]))
if (any(psis_part$diagnostics$pareto_k > 0.7)) {
# refit the model based on the first i observations
# could be improved by computed exact loo for the ith observation
i_refit <- i
fit_part <- update(fit_part, newdata = df[1:i, ], recompile = FALSE)
loglik[, i] <- log_lik(fit_part, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
psis_part <- suppressWarnings(psis(logr[, i:i_refit]))
}
w_i <- exp(psis_part$log_weights[, 1])
approx_elpds[i] <- log(sum(exp(loglik[, i]) * w_i) / sum(w_i))
}
(approx_elpd <- sum(approx_elpds[-(1:L)]))
plot(psis(logr[, -(1:L)]))
fit_ar1
loglik <- logr <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
approx_elpds <- rep(NA, nrow(df))
fit_part <- fit_ar1
i_refit <- N
for (i in N:(L + 1)) {
loglik[, i] <- log_lik(fit_part, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
psis_part <- suppressWarnings(psis(logr[, i:i_refit]))
if (any(psis_part$diagnostics$pareto_k > 0.7)) {
# refit the model based on the first i observations
# could be improved by computed exact loo for the ith observation
i_refit <- i
fit_part <- update(fit_part, newdata = df[1:i, ], recompile = FALSE)
loglik[, i] <- log_lik(fit_part, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
psis_part <- suppressWarnings(psis(logr[, i:i_refit]))
}
w_i <- exp(psis_part$log_weights[, 1])
approx_elpds[i] <- log(sum(exp(loglik[, i]) * w_i) / sum(w_i))
}
# Chunk 1: setup
knitr::opts_chunk$set(
cache=TRUE,
message=FALSE,
error=FALSE,
warning=FALSE,
comment=NA,
dev = "png",
dpi = 150,
fig.asp = 0.618,
fig.width = 5,
out.width = "60%",
fig.align = "center"
)
library(brms)
library(loo)
set.seed(1234)
# Chunk 2
df <- data.frame(y = arima.sim(list(ar = c(0.5, -0.3)), 100) + 5, t = 1:100)
df$ym1 <- c(0, df$y[-nrow(df)])
ggplot(df, aes(t, y)) + geom_line()
# Chunk 3: fit_ar1
# fit_ar1 <- brm(y ~ 1, df, autocor = cor_ar(~t))
fit_ar1 <- brm(y ~ ym1, df)
# Chunk 4
pred <- cbind(df, predict(fit_ar1))
names(pred) <- make.names(names(pred))
ggplot(pred, aes(t, Estimate)) +
geom_smooth(
aes(ymin = X2.5.ile, ymax = X97.5.ile),
stat = "identity"
) +
geom_point(aes(t, y), inherit.aes = FALSE)
loglik <- logr <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
approx_elpds <- rep(NA, nrow(df))
fit_part <- fit_ar1
i_refit <- N
for (i in N:(L + 1)) {
loglik[, i] <- log_lik(fit_part, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
psis_part <- suppressWarnings(psis(logr[, i:i_refit]))
if (any(psis_part$diagnostics$pareto_k > 0.7)) {
# refit the model based on the first i observations
# could be improved by computed exact loo for the ith observation
i_refit <- i
fit_part <- update(fit_part, newdata = df[1:i, ], recompile = FALSE)
loglik[, i] <- log_lik(fit_part, newdata = df[i, ])
logr[, i] <- - rowSums(loglik[, i:i_refit, drop = FALSE])
psis_part <- suppressWarnings(psis(logr[, i:i_refit]))
}
w_i <- exp(psis_part$log_weights[, 1])
approx_elpds[i] <- log(sum(exp(loglik[, i]) * w_i) / sum(w_i))
}
plot(psis(logr[, -(1:L)]))
(approx_elpd <- sum(approx_elpds[-(1:L)]))
loglik <- matrix(nrow = nsamples(fit_ar1), ncol = nrow(df))
for (i in N:(L + 1)) {
fit_i <- update(fit_ar1, newdata = df[-(i:N), ], recompile = FALSE)
loglik[, i] <- log_lik(fit_i, newdata = df[i, ])
}
log_mean_exp <- function(x) {
# more stable than log(mean(exp(x)))
max_x <- max(x)
max_x + log(sum(exp(x - max_x))) - log(length(x))
}
exact_elpds <- apply(loglik, 2, log_mean_exp)
(exact_elpd <- sum(exact_elpds[-(1:L)]))
(100 - 4 + 1)
unlink('m-step-ahead-predictions_cache', recursive = TRUE)
unlink('m-step-ahead-predictions_cache', recursive = TRUE)
unlink('m-step-ahead-predictions_cache', recursive = TRUE)
unlink('m-step-ahead-predictions_cache', recursive = TRUE)
